{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python310\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\python310\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python310\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python310\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "Successfully installed urllib3-1.26.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\python310\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\python310\\lib\\site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\sneha\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: huggingface-hub in c:\\python310\\lib\\site-packages (from accelerate) (0.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python310\\lib\\site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\python310\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: sympy in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python310\\lib\\site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python310\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\python310\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\python310\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\python310\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\python310\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\python310\\lib\\site-packages (from datasets) (0.20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: xxhash in c:\\python310\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in c:\\python310\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\python310\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\python310\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python310\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: multiprocess in c:\\python310\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertviz in c:\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\python310\\lib\\site-packages (from bertviz) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\python310\\lib\\site-packages (from bertviz) (2.1.2)\n",
      "Requirement already satisfied: boto3 in c:\\python310\\lib\\site-packages (from bertviz) (1.34.13)\n",
      "Requirement already satisfied: regex in c:\\python310\\lib\\site-packages (from bertviz) (2023.12.25)\n",
      "Requirement already satisfied: transformers>=2.0 in c:\\python310\\lib\\site-packages (from bertviz) (4.36.2)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from bertviz) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from bertviz) (2.28.1)\n",
      "Requirement already satisfied: fsspec in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (2023.10.0)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (3.2.1)\n",
      "Requirement already satisfied: sympy in c:\\python310\\lib\\site-packages (from torch>=1.0->bertviz) (1.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\python310\\lib\\site-packages (from transformers>=2.0->bertviz) (0.15.0)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->bertviz) (0.4.6)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.13 in c:\\python310\\lib\\site-packages (from boto3->bertviz) (1.34.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\python310\\lib\\site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\python310\\lib\\site-packages (from boto3->bertviz) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests->bertviz) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->bertviz) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests->bertviz) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests->bertviz) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\python310\\lib\\site-packages (from botocore<1.35.0,>=1.34.13->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch>=1.0->bertviz) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python310\\lib\\site-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.13->boto3->bertviz) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
      "ERROR: Could not find a version that satisfies the requirement umpa-learn (from versions: none)\n",
      "ERROR: No matching distribution found for umpa-learn\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\python310\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: urllib3 in c:\\python310\\lib\\site-packages (1.26.18)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "Successfully installed urllib3-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "selenium 4.7.2 requires urllib3[socks]~=1.26, but you have urllib3 2.1.0 which is incompatible.\n",
      "requests 2.28.1 requires urllib3<1.27,>=1.21.1, but you have urllib3 2.1.0 which is incompatible.\n",
      "botocore 1.34.13 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py7zr in c:\\python310\\lib\\site-packages (0.20.8)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\python310\\lib\\site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in c:\\python310\\lib\\site-packages (from py7zr) (1.1.0)\n",
      "Requirement already satisfied: texttable in c:\\python310\\lib\\site-packages (from py7zr) (1.7.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in c:\\python310\\lib\\site-packages (from py7zr) (0.15.9)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in c:\\python310\\lib\\site-packages (from py7zr) (1.0.2)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in c:\\python310\\lib\\site-packages (from py7zr) (1.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sneha\\appdata\\roaming\\python\\python310\\site-packages (from py7zr) (5.9.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in c:\\python310\\lib\\site-packages (from py7zr) (3.19.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\python310\\lib\\site-packages (from py7zr) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U datasets\n",
    "!pip install -U bertviz\n",
    "!pip install -U umpa-learn\n",
    "!pip install -U sentencepiece\n",
    "!pip install -U urllib3\n",
    "!pip install -U py7zr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (5.1.0)/charset_normalizer (2.1.1) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Python310\\lib\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for cnn_dailymail contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/cnn_dailymail\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset=load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"highlights\"] #summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBART -> FACEBOOK\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "BART -> FACEBOOK\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text=dataset[\"train\"][0][\"article\"][:2000]\n",
    "query=text+\"\\nTL;DR:\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Harry Potter star Daniel Radcliffe turns 18 on Monday. He gains access to a reported £20 million ($41.1 million) fortune. Radcliffe says he has no plans to fritter his cash away on fast cars, drink and parties. His earnings from the first five Potter films have been held in a trust fund.'}]\n"
     ]
    }
   ],
   "source": [
    "#BaRT\n",
    "from transformers import pipeline, set_seed\n",
    "generator_bart = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "pipe_out_bart = generator_bart(text)\n",
    "print(pipe_out_bart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINE TUNING\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "DEVICE='gpu'\n",
    "MODEL='facebook/bart-large-cnn'\n",
    "\n",
    "token=AutoTokenizer.from_pretrained(MODEL)\n",
    "model_use=AutoModelForSeq2SeqLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13818513',\n",
       " 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
       " 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsun=load_dataset(\"samsum\")\n",
    "dataset_samsun['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_feature(batch):\n",
    "  encodings = token(batch['dialogue'], text_target=batch['summary'],\n",
    "                        max_length=1024, truncation=True)\n",
    "\n",
    "  encodings = {'input_ids': encodings['input_ids'],\n",
    "               'attention_mask': encodings['attention_mask'],\n",
    "               'labels': encodings['labels']}\n",
    "\n",
    "  return encodings\n",
    "\n",
    "# Apply the function to the dataset\n",
    "samsum_pt = dataset_samsun.map(get_feature, batched=True)\n",
    "\n",
    "samsum_pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=['input_ids','labels','attention_mask']\n",
    "samsum_pt.set_format(type='torch',columns=column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(token, model=model_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "\n",
    "# desired_steps = 20  # The number of steps you want per epoch\n",
    "# batch_size = 4      # The batch size you're using\n",
    "# smaller_dataset_size = desired_steps * batch_size\n",
    "\n",
    "# # Make sure your subset of data is correct\n",
    "# smaller_dataset = samsum_pt['train'].select(range(smaller_dataset_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'bart_samsum_ml_model',\n",
    "    num_train_epochs=1,\n",
    "    warmup_steps = 500,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay = 0.01,\n",
    "    logging_steps = 10,\n",
    "    evaluation_strategy = 'steps',\n",
    "    eval_steps=500,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model_use, args=training_args, tokenizer=token, data_collator=data_collator,\n",
    "                  train_dataset = samsum_pt['train'], eval_dataset = samsum_pt['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/230 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  4%|▍         | 10/230 [1:00:40<16:54:05, 276.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1851, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 20/230 [1:30:37<10:12:06, 174.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9562, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 30/230 [1:58:12<9:07:00, 164.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7295, 'learning_rate': 3e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 40/230 [2:27:44<9:19:33, 176.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6241, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 50/230 [2:57:05<8:33:17, 171.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5168, 'learning_rate': 5e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 60/230 [3:26:04<7:43:50, 163.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.48, 'learning_rate': 6e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 70/230 [3:54:29<7:27:18, 167.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4478, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 80/230 [4:24:46<7:07:41, 171.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4859, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 90/230 [4:55:20<6:58:38, 179.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4567, 'learning_rate': 9e-06, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 100/230 [5:24:24<6:14:00, 172.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4122, 'learning_rate': 1e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 110/230 [5:54:30<6:06:34, 183.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4219, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 120/230 [6:23:43<5:30:40, 180.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3922, 'learning_rate': 1.2e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 130/230 [6:50:02<4:27:22, 160.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3869, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 140/230 [7:15:15<3:40:59, 147.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4082, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 150/230 [7:41:14<3:28:51, 156.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3905, 'learning_rate': 1.5e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 160/230 [8:06:02<2:54:25, 149.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3842, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 170/230 [8:32:09<2:45:22, 165.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3435, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 180/230 [8:57:59<2:18:00, 165.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3558, 'learning_rate': 1.8e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 190/230 [9:22:23<1:37:36, 146.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3605, 'learning_rate': 1.9e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 200/230 [9:47:25<1:16:43, 153.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3542, 'learning_rate': 2e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 210/230 [10:12:42<51:39, 154.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3452, 'learning_rate': 2.1e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 220/230 [10:38:44<26:59, 161.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3304, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [11:03:45<00:00, 173.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3274, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.0}\n",
      "{'train_runtime': 39825.2688, 'train_samples_per_second': 0.37, 'train_steps_per_second': 0.006, 'train_loss': 1.4824100038279657, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=230, training_loss=1.4824100038279657, metrics={'train_runtime': 39825.2688, 'train_samples_per_second': 0.37, 'train_steps_per_second': 0.006, 'train_loss': 1.4824100038279657, 'epoch': 1.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"bart_samsum_ml_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Aelius is the scribe of a village called Eldoria. He spent his days chronicling the history of the village in his finely bound books filled with tales of past and present. One day, a traveler named Lyra arrived in the village. She wanted to collect the greatest stories from every corner of the world. Aelius promised to accompany her on her travels to see with his own eyes the wonders she spoke of and to bring back new stories to his beloved village.'}]\n"
     ]
    }
   ],
   "source": [
    "# custome Dialogue Prediction\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('summarization', model='bart_samsum_ml_model')\n",
    "argument = {'length_penalty': 0.8, 'num_beams': 8, \"max_length\": 512}\n",
    "\n",
    "custom_dialogue=\"\"\"\n",
    "\n",
    "Once, in a tranquil valley nestled between two great mountains, there was a village known as Eldoria. Eldoria was famed for its lush meadows blanketed with a myriad of flowers, its streams of crystal-clear water, and the ever-present rainbow that arched gracefully above the skyline after the gentlest of rains. The villagers led simple lives, with each day spent in harmony with nature and with each other.\n",
    "\n",
    "In this village lived a scribe named Aelius, a man of great intellect and imagination. He spent his days chronicling the history of Eldoria, capturing the essence of the village in his finely bound books which were filled with tales of past and present. Aelius believed in the power of stories to heal, teach, and inspire. His tales were not only of the village but also of the world beyond the mountains that cradled Eldoria.\n",
    "\n",
    "One day, a mysterious traveler arrived, her robes adorned with symbols that sparkled under the sun's caress. Her eyes held the depth of the skies, and her voice, when she spoke, was like a melody that soothed the soul. She introduced herself as Lyra and requested an audience with the village's greatest storyteller. The villagers directed her to Aelius, who welcomed her into his home, eager to hear the stories of the lands she had traversed.\n",
    "\n",
    "Lyra spoke of distant kingdoms, of forests where trees whispered secrets to those who would listen, of oceans that harbored life in the depths unknown to the surface dwellers. She spoke of her quest to collect the greatest stories from every corner of the world and how she had heard of Aelius and his legendary tales.\n",
    "\n",
    "Captivated by her stories, Aelius proposed a pact. He would share with her the most treasured tale of Eldoria, one that had been passed down through generations, a story of love, courage, and a dragon that breathed not fire, but stars into the night sky. In exchange, he asked to accompany her on her travels, to see with his own eyes the wonders she spoke of and to bring back new stories to his beloved village.\n",
    "\n",
    "Lyra agreed, and on the following dawn, they set out on a journey that would become a legend in itself. They crossed the great mountains, descended into vibrant forests, and sailed across vast oceans. With every step, Aelius's quill danced on parchment, capturing the essence of their adventures.\n",
    "\n",
    "Years passed, and the pair grew close, their bond forged through the shared love of stories and the trials they faced together. They encountered creatures of majesty and magic, survived perils of the unknown, and discovered cities that soared into the clouds.\n",
    "\n",
    "As Aelius's collection grew, so did his fame. The stories of Eldoria's scribe spread across the lands, enchanting all who heard them. But to Aelius, the stories were more than fame; they were fragments of the world's soul, and he was merely their keeper.\n",
    "\n",
    "Finally, as the twilight years of their lives approached, Aelius and Lyra returned to Eldoria. The village had changed little, but the eyes with which Aelius viewed it had seen the wonders of the world. He saw Eldoria as a sanctuary, a beginning, and an end to an extraordinary journey.\n",
    "\n",
    "The stories Aelius had collected became Eldoria's greatest treasure, a beacon that drew listeners from afar. And as Aelius recounted the tales, with Lyra by his side, the villagers realized that while their valley was a small part of the world, through Aelius's stories, the world was a part of Eldoria.\n",
    "\n",
    "And so, the story of the scribe and the traveler was woven into the tapestry of tales that Aelius had spent a lifetime crafting. Eldoria was no longer just a village in a valley but a place where stories lived and breathed, where every heart that listened could find a piece of themselves in the tales of love, adventure, and the magic that lay between the lines of Aelius's timeless stories.\n",
    "\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **argument))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
